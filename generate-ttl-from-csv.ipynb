{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages, initialize sentence tokenization resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bradleyallen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bradleyallen/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/bradleyallen/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/bradleyallen/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, rdflib, re, nltk, collections\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "from slugify import slugify\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV file for ABR A list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('edited-csv/A.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract entity names and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize all whitespace to spaces in notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['notes'] = df['notes'].str.replace('\\s', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['place'] = df['publication'].str.extract('(.+)\\:', expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['publisher'] = df['publication'].str.extract('\\: (.+)', expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['copyrightDate'] = df['notes'].str.extract('©(\\w+)', expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MaynardAndMiles'] = df['notes'].str.extract('\\{M\\&M (\\S*)\\}', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Schottlaender'] = df['work'] + df['instance'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bindings (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['binding'] = df['notes'].str.extract('([A-Z]\\S+bound[^.]*)\\.', expand=False)\n",
    "df['binding'] = df['binding'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hardbound                                                                                                1\n",
       "Hardbound (issued without dustjacket)                                                                    2\n",
       "Hardbound (issued without dustjacket), and softbound                                                     4\n",
       "Hardbound in dustjacket                                                                                 17\n",
       "Hardbound in dustjacket (no softbound issued)                                                            7\n",
       "Hardbound in dustjacket, and softbound                                                                  19\n",
       "Hardbound in dustjacket, issued with compact disc bound in rear                                          1\n",
       "Hardbound in tissue dustjacket, and softbound                                                            1\n",
       "Hardbound with hand-made orange tissue guards inserted                                                   1\n",
       "Hardbound, and softbound                                                                                 3\n",
       "Hardbound, issued without dust jacket                                                                    1\n",
       "Hardbound, issued without dustjacket                                                                     2\n",
       "Hardbound, issued without dustjacket in Side A, white; Side B, black;  matrix number: UB LP 1 A S/S]     1\n",
       "Hardbound; handbound (issued without dustjacket in slipcase)                                             1\n",
       "Softbound                                                                                               54\n",
       "Softbound (no hardbound issued)                                                                         54\n",
       "Softbound in dustjacket (no hardbound issued)                                                            4\n",
       "Softbound with dustjacket (no hardbound issued)                                                          1\n",
       "Softbound; handbound (no hardbound issued)                                                               1\n",
       "Staplebound                                                                                              5\n",
       "Staplebound (no hardbound issued)                                                                       12\n",
       "Staplebound mimeograph  (no hardbound issued)                                                            1\n",
       "Staplebound pamphlet                                                                                     2\n",
       "Name: binding, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['binding'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promotional materials (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['promotionalMaterial'] = df['notes'].str.extract(' 1. (\\[.+$)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schottlaender</th>\n",
       "      <th>promotionalMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A2b</td>\n",
       "      <td>[Prospectus]. New York: Grove Press, [1962]. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A24a</td>\n",
       "      <td>[Prospectus]. In English and French. Ingatesto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A24b</td>\n",
       "      <td>[Prospectus]. Göttingen: Expanded Media Editio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>A42a</td>\n",
       "      <td>[Prospectus]. Santa Barbara, Calif.: Bradford ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>A54a</td>\n",
       "      <td>[Promotional Postcard]. San Francisco: City Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>A56a</td>\n",
       "      <td>[Press Kit]. New York: Holt, Rinehart and Wins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>A59a</td>\n",
       "      <td>[Press Release]. New York: Viking Penguin, [19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>A65a</td>\n",
       "      <td>[Promotional Postcard] a. Berkeley, Calif.: Sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>A66a</td>\n",
       "      <td>[Prospectus]. New York: Whitney Museum of Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>A66b</td>\n",
       "      <td>[Promotional Poster]. [New York]: High Risk Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>A82a</td>\n",
       "      <td>[Promotional Postcard]. [New York: The Center ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Schottlaender                                promotionalMaterial\n",
       "12            A2b  [Prospectus]. New York: Grove Press, [1962]. P...\n",
       "95           A24a  [Prospectus]. In English and French. Ingatesto...\n",
       "96           A24b  [Prospectus]. Göttingen: Expanded Media Editio...\n",
       "140          A42a  [Prospectus]. Santa Barbara, Calif.: Bradford ...\n",
       "160          A54a  [Promotional Postcard]. San Francisco: City Li...\n",
       "162          A56a  [Press Kit]. New York: Holt, Rinehart and Wins...\n",
       "174          A59a  [Press Release]. New York: Viking Penguin, [19...\n",
       "190          A65a  [Promotional Postcard] a. Berkeley, Calif.: Sm...\n",
       "191          A66a  [Prospectus]. New York: Whitney Museum of Amer...\n",
       "192          A66b  [Promotional Poster]. [New York]: High Risk Bo...\n",
       "213          A82a  [Promotional Postcard]. [New York: The Center ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.promotionalMaterial.notnull()][['Schottlaender', 'promotionalMaterial']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze even more data out of notes using more nuanced NLP (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instances = df.where((pd.notnull(df)), None).to_dict('records')\n",
    "for i in instances:\n",
    "    #print(i['Schottlaender'])\n",
    "    notes = i['notes']\n",
    "    if notes:\n",
    "        notes_text = nltk.sent_tokenize(notes)\n",
    "        for sentence in notes_text:\n",
    "            tokenized = nltk.word_tokenize(sentence)\n",
    "            tagged = nltk.pos_tag(tokenized)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BIBFRAME Turtle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abri = rdflib.Namespace(\"https://w3id.org/anything-but-routine/4.0/instance/\")\n",
    "abrw = rdflib.Namespace(\"https://w3id.org/anything-but-routine/4.0/work/\")\n",
    "bf = rdflib.Namespace(\"http://id.loc.gov/ontologies/bibframe/\")\n",
    "arm = rdflib.Namespace(\"https://w3id.org/arm/core/ontology/0.1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to initialize graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_abr_graph():\n",
    "    g = rdflib.Graph()\n",
    "    g.bind(\"abri\", \"https://w3id.org/anything-but-routine/4.0/instance/\")\n",
    "    g.bind(\"abrw\", \"https://w3id.org/anything-but-routine/4.0/work/\")\n",
    "    g.bind(\"bf\", \"http://id.loc.gov/ontologies/bibframe/\")\n",
    "    g.bind(\"arm\", \"https://w3id.org/arm/core/ontology/0.1/\")\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 705 ms, total: 18.8 s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "instances = df.where((pd.notnull(df)), None).to_dict('records')\n",
    "work_to_instance_map = collections.defaultdict(list)\n",
    "\n",
    "for i in instances:\n",
    "    g = initialize_abr_graph()\n",
    "    name = i['Schottlaender']\n",
    "    work_to_instance_map[i['work']].append(name)\n",
    "    id = abri[name]\n",
    "    g.add((id, RDF.type, bf.Instance))\n",
    "    g.add((id, RDFS.label, Literal(i['workTitle'])))\n",
    "    g.add((id, bf.instanceOf, abrw[i['work']]))\n",
    "    # bf.contributor\n",
    "    wsb = BNode()\n",
    "    g.add((id, bf.contributor, wsb))\n",
    "    g.add((wsb, RDF.type, bf.Agent))\n",
    "    g.add((wsb, RDF.type, bf.Person))\n",
    "    g.add((wsb, bf.role, Literal(\"author\")))\n",
    "    g.add((wsb, RDFS.label, Literal(\"William S. Burroughs\")))\n",
    "    # bf:title\n",
    "    title = BNode()\n",
    "    g.add((id, bf.title, title))\n",
    "    g.add((title, RDF.type, bf.Title))\n",
    "    g.add((title, RDFS.label, Literal(i['instanceTitle'])))\n",
    "    # bf:identifiedBy\n",
    "    schottlaender_id = BNode()\n",
    "    g.add((id, bf.identifiedBy, schottlaender_id))\n",
    "    g.add((schottlaender_id, RDF.type, bf.Identifier))\n",
    "    g.add((schottlaender_id, bf.source, Literal(\"Schottlaender v4.0\")))\n",
    "    g.add((schottlaender_id, RDF.value, Literal(name)))\n",
    "    m_n_m = i['MaynardAndMiles']\n",
    "    if m_n_m:\n",
    "        m_n_m_id = BNode()\n",
    "        g.add((id, bf.identifiedBy, m_n_m_id))\n",
    "        g.add((m_n_m_id, RDF.type, bf.Identifier))\n",
    "        g.add((m_n_m_id, bf.source, Literal(\"Maynard & Miles\")))\n",
    "        g.add((m_n_m_id, RDF.value, Literal(m_n_m)))\n",
    "    # bf:note\n",
    "    notes = i['notes']\n",
    "    if notes:\n",
    "        notes_text = nltk.sent_tokenize(notes)\n",
    "        for sentence in notes_text:\n",
    "            note = BNode()\n",
    "            g.add((id, bf.note, note))\n",
    "            g.add((note, RDF.type, bf.Note))\n",
    "            g.add((note, RDF.value, Literal(sentence)))\n",
    "            # Contributors extracted from note\n",
    "            tokenized = nltk.word_tokenize(sentence)\n",
    "            tagged = nltk.pos_tag(tokenized)\n",
    "            namedEnt = nltk.ne_chunk(tagged)\n",
    "            for t in namedEnt.subtrees():\n",
    "                if t.label() == 'PERSON':\n",
    "                    person_tokens = [ c[0] for c in t ]\n",
    "                    person_name = ' '.join(person_tokens)\n",
    "                    person = BNode()\n",
    "                    g.add((id, bf.contributor, person))\n",
    "                    g.add((person, RDF.type, bf.Agent))\n",
    "                    g.add((person, RDF.type, bf.Person)) \n",
    "                    g.add((person, bf.role, Literal(\"contributor\")))\n",
    "                    g.add((person, RDFS.label, Literal(person_name)))\n",
    "    # bf:provisionActivity\n",
    "    publisher = i['publisher']\n",
    "    date = i['date']\n",
    "    place = i['place']\n",
    "    if publisher and date and place:\n",
    "        pa_lit = BNode()\n",
    "        g.add((id, bf.provisionActivity, pa_lit))\n",
    "        g.add((pa_lit, RDF.type, bf.ProvisionActivity))\n",
    "        g.add((pa_lit, RDF.type, bf.Publication))\n",
    "        g.add((pa_lit, bf.agent, Literal(publisher)))\n",
    "        g.add((pa_lit, bf.date, Literal(date)))\n",
    "        g.add((pa_lit, bf.place, Literal(place)))\n",
    "    # bf:copyrightDate\n",
    "    copyrightDate = i['copyrightDate']\n",
    "    if copyrightDate:\n",
    "        g.add((id, bf.copyrightDate, Literal(copyrightDate)))\n",
    "    g.serialize(f\"ttl/instance/{name}.ttl\", format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "works = pd.DataFrame(df[['workTitle', 'work']]).drop_duplicates().to_dict('records')\n",
    "\n",
    "for work in works:\n",
    "    g = initialize_abr_graph()\n",
    "    name = work['work']\n",
    "    id = abrw[name]\n",
    "    g.add((id, RDF.type, bf.Work))\n",
    "    g.add((id, RDF.type, bf.Text))\n",
    "    g.add((id, RDFS.label, Literal(work['workTitle'])))\n",
    "    wsb = BNode()\n",
    "    g.add((id, bf.contributor, wsb))\n",
    "    g.add((wsb, RDF.type, bf.Agent))\n",
    "    g.add((wsb, RDF.type, bf.Person)) \n",
    "    g.add((wsb, bf.role, Literal(\"author\")))\n",
    "    g.add((wsb, RDFS.label, Literal(\"William S. Burroughs\")))\n",
    "    for inst in work_to_instance_map[name]:\n",
    "        g.add((id, bf.hasInstance, abri[inst]))\n",
    "    g.serialize(f\"ttl/work/{name}.ttl\", format='turtle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wsbhack]",
   "language": "python",
   "name": "conda-env-wsbhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
